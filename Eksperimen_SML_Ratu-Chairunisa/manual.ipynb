{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZLRMFl0JyyQ"
      },
      "source": [
        "# **1. Perkenalan Dataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hssSDn-5n3HR"
      },
      "source": [
        "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
        "\n",
        "1. **Sumber Dataset**:  \n",
        "   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **2. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start due to the missing module 'IPython'. Consider installing this module.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **3. Memuat Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
        "\n",
        "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
        "\n",
        "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHCGNTyrM5fS",
        "outputId": "f57a5ebc-9304-4cb6-c2c0-639b379e9504"
      },
      "outputs": [],
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhamedumarjamil/crypto-and-gold-prices-dataset-20152025\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tKQs7SnG3E9U",
        "outputId": "d7141ca1-ae0a-4144-ecfb-636aceb81e10"
      },
      "outputs": [],
      "source": [
        " = pd.read_csv('/kaggle/input/df/crypto-and-gold-prices-dataset-20152025/Crypto Data Since 2015.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvUYCz7a600v"
      },
      "outputs": [],
      "source": [
        "# Date ke datetime & set index\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgZkbJLpK9UR"
      },
      "source": [
        "# **4. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
        "\n",
        "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "9yaq1yyVBuEI",
        "outputId": "47c42ebb-ced6-43ed-94a4-5cfc1dc6cc51"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Tren Harga\n",
        "plt.figure(figsize=(14, 7))\n",
        "symbols_to_plot = [\"Bitcoin (USD)\", \"Ethereum (USD)\", \"Gold (USD per oz)\"]\n",
        "for symbol in symbols_to_plot:\n",
        "    plt.plot(\n",
        "        df.index,\n",
        "        df[symbol],\n",
        "        label=symbol\n",
        "    )\n",
        "plt.title(\"Tren Harga Close Bitcoin, Etherum, & Emas (2015–2025)\")\n",
        "plt.xlabel(\"Tahun\")\n",
        "plt.ylabel(\"Harga (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "8GoQnB0HCuo3",
        "outputId": "c4b185b3-db71-4f63-976e-6a93db0ac922"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Tren Harga\n",
        "plt.figure(figsize=(14, 7))\n",
        "symbols_to_plot = [\"Cardano (ADA)\", \"Binance Coin (BNB)\", \"Ripple (XRP)\", \"Dogecoin (DOGE)\", \"Solana (SOL)\"]\n",
        "for symbol in symbols_to_plot:\n",
        "    plt.plot(\n",
        "        df.index,\n",
        "        df[symbol],\n",
        "        label=symbol\n",
        "    )\n",
        "plt.title(\"Tren Harga Close Kripto Lainnya (2015–2025)\")\n",
        "plt.xlabel(\"Tahun\")\n",
        "plt.ylabel(\"Harga (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c45PAEOtGDuG",
        "outputId": "9a205451-d587-4a75-b174-3623c4a37f0c"
      },
      "outputs": [],
      "source": [
        "# Calculate daily returns\n",
        "daily_returns = df.pct_change().dropna()\n",
        "\n",
        "# Loop to display the daily returns plot for each crypto\n",
        "for column in daily_returns.columns:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(daily_returns.index, daily_returns[column], label=f\"{column}\", color=\"tab:red\")\n",
        "\n",
        "    plt.title(f\"Daily Returns - {column}\", fontsize=14)\n",
        "    plt.xlabel(\"Tahun\")\n",
        "    plt.ylabel(\"Return Harian\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "6SeLbBt3EB3u",
        "outputId": "c80e8cf3-4aa9-464c-8b98-64fea85f1df0"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = daily_returns.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "plt.title(\"Korelasi Daily Returns Antar Kripto dan Emas\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpgHfgnSK3ip"
      },
      "source": [
        "# **5. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COf8KUPXLg5r"
      },
      "source": [
        "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
        "\n",
        "Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.\n",
        "\n",
        "Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:\n",
        "1. Menghapus atau Menangani Data Kosong (Missing Values)\n",
        "2. Menghapus Data Duplikat\n",
        "3. Normalisasi atau Standarisasi Fitur\n",
        "4. Deteksi dan Penanganan Outlier\n",
        "5. Encoding Data Kategorikal\n",
        "6. Binning (Pengelompokan Data)\n",
        "\n",
        "Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "_gbTir7RHMB8",
        "outputId": "01615b95-60d9-4a62-c49f-b4627df098e5"
      },
      "outputs": [],
      "source": [
        "# Melihat missing value\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne7FtHICHQK0",
        "outputId": "20913d09-816e-45ff-f123-55c272fa4fa5"
      },
      "outputs": [],
      "source": [
        "# Melihat data duplikat\n",
        "print(\"Jumlah data duplikat:\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EUwT7yfwHz-u",
        "outputId": "ae767e24-b4ca-4037-88d9-31b5b4456093"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM34d8UgY1mp"
      },
      "outputs": [],
      "source": [
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "data = df.values\n",
        "data = normalize_series(data, data.min(axis=0), data.max(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsuWtnsJZCk2",
        "outputId": "2478464a-200a-424c-c59d-528e812c23ab"
      },
      "outputs": [],
      "source": [
        "selected_columns = [\"Bitcoin (USD)\", \"Ethereum (USD)\", \"Gold (USD per oz)\", \"Cardano (ADA)\", \"Binance Coin (BNB)\", \"Ripple (XRP)\", \"Dogecoin (DOGE)\", \"Solana (SOL)\"]\n",
        "N_FEATURES = len(selected_columns)\n",
        "print(\"jumlah fitur yang digunakan:\", N_FEATURES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3YLoR-Ekw7B"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35fe6cb3"
      },
      "outputs": [],
      "source": [
        "# Split data into training and validation sets\n",
        "train_size = int(len(data) * 0.8)\n",
        "x_train, x_valid = data[0:train_size], data[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_R4m3bVbQo-"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "N_PAST = 30\n",
        "N_FUTURE = 30\n",
        "SHIFT = 1\n",
        "# Kode untuk membuat windowed datasets\n",
        "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFTWFNnSbVqf"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV1j_ephjxKh",
        "outputId": "6cfdf6d4-729f-43fd-f2ed-0171019cc77b"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(N_PAST, N_FEATURES)),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(N_FUTURE * N_FEATURES), # Change units to N_FUTURE * N_FEATURES\n",
        "    tf.keras.layers.Reshape((N_FUTURE, N_FEATURES))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkrXs63ubnG0"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if (logs.get('mae') < 0.055 and logs.get('val_mae') < 0.055):\n",
        "                self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAR8ZXnJbtxX"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss='mae',\n",
        "                  optimizer= optimizer,\n",
        "                  metrics=[\"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvAdn2dqbwvV",
        "outputId": "be4f31c5-35cf-446e-d1fc-9f89a2d11948"
      },
      "outputs": [],
      "source": [
        "model.fit(train_set,\n",
        "          validation_data=(valid_set),\n",
        "          epochs=100,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSym_nLLb6PM",
        "outputId": "3cc88fea-e68f-41a4-b6f9-e579886f5f6e"
      },
      "outputs": [],
      "source": [
        "train_pred = model.predict(train_set)\n",
        "train_pred[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fDKNbu2UzS_M",
        "outputId": "5432d0f7-1b59-4e14-c232-d95be643ec4e"
      },
      "outputs": [],
      "source": [
        "crypto_names = [\"BTC\", \"ETH\", \"GOLD\", \"ADA\", \"BNB\", \"XRP\", \"DOGE\", \"SOL\"]\n",
        "train_pred = model.predict(train_set)\n",
        "predictions = train_pred[0]   # shape (N_FUTURE, n_crypto)\n",
        "\n",
        "# Data tanggal\n",
        "last_date = pd.to_datetime(\"2025-07-24\")   # data terakhir\n",
        "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1),\n",
        "                             periods=len(predictions), freq=\"D\")\n",
        "\n",
        "# Visualisasi Subplot\n",
        "n_crypto = len(crypto_names)\n",
        "n_cols = 2\n",
        "n_rows = int(np.ceil(n_crypto / n_cols))\n",
        "\n",
        "plt.figure(figsize=(14, 3 * n_rows))\n",
        "\n",
        "for i, crypto in enumerate(crypto_names):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.plot(future_dates, predictions[:, i], marker=\"o\",  linewidth=2, label=crypto, color=\"tab:red\")\n",
        "    plt.title(f\"Prediksi {crypto} 30 Hari ke Depan (Mulai 25 Juli 2025)\")\n",
        "    plt.xlabel(\"Tanggal\")\n",
        "    plt.ylabel(\"Harga (Normalized)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "SMSML_Ratu_Chairunisa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
